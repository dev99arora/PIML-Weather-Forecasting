{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "T0j_pwlAJPKF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2a8982f-46bb-4c0a-e6ce-c2c302dd5e9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install netCDF4\n",
        "!pip install xarray"
      ],
      "metadata": {
        "id": "awePe6gaJfnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ef68084-2e9b-490c-cf21-9863d53bbd32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting netCDF4\n",
            "  Downloading netCDF4-1.6.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from netCDF4) (1.22.4)\n",
            "Collecting cftime\n",
            "  Downloading cftime-1.6.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m79.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: cftime, netCDF4\n",
            "Successfully installed cftime-1.6.2 netCDF4-1.6.3\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xarray in /usr/local/lib/python3.9/dist-packages (2022.12.0)\n",
            "Requirement already satisfied: pandas>=1.3 in /usr/local/lib/python3.9/dist-packages (from xarray) (1.5.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.9/dist-packages (from xarray) (23.1)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.9/dist-packages (from xarray) (1.22.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.3->xarray) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.3->xarray) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.8.1->pandas>=1.3->xarray) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "1cBRHMd_yHYz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuk3AowHJLsX"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import netCDF4 as nc\n",
        "import scipy.io as sio\n",
        "import xarray as xr\n",
        "import pickle\n",
        "from scipy.stats import pearsonr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNZzime2JLsd"
      },
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "import keras.backend as K\n",
        "import netCDF4\n",
        "import numpy as np\n",
        "from keras.layers import Input, Convolution2D, Convolution1D, MaxPooling2D, Dense, Dropout, \\\n",
        "                          Flatten, concatenate, Activation, Reshape, \\\n",
        "                          UpSampling2D,ZeroPadding2D\n",
        "import keras\n",
        "from keras.callbacks import History\n",
        "history = History()\n",
        "\n",
        "import keras\n",
        "from keras.layers import Conv2D, Conv2DTranspose, Cropping2D, Concatenate, ZeroPadding2D\n",
        "from keras.models import load_model\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras.layers import Activation\n",
        "from keras.layers import MaxPool2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "\n",
        "# from utils import get_initial_weights\n",
        "# from layers import BilinearInterpolation\n",
        "\n",
        "__version__ = 0.1 "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Getting weights for spatial transofmer module's affine transformation theta\n",
        "def get_initial_weights(output_size):\n",
        "    b = np.zeros((2, 3), dtype='float32')\n",
        "    b[0, 0] = 1\n",
        "    b[1, 1] = 1\n",
        "    W = np.zeros((output_size, 6), dtype='float32')\n",
        "    weights = [W, b.flatten()]\n",
        "    return weights"
      ],
      "metadata": {
        "id": "rf_aEYl5KXGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras.backend as K\n",
        "#from keras.engine.topology import Layer\n",
        "from tensorflow.python.keras.layers import Layer\n",
        "\n",
        "if K.backend() == 'tensorflow':\n",
        "    import tensorflow as tf\n",
        "\n",
        "    def K_meshgrid(x, y):\n",
        "        return tf.meshgrid(x, y)\n",
        "\n",
        "    def K_linspace(start, stop, num):\n",
        "        return tf.linspace(start, stop, num)\n",
        "\n",
        "else:\n",
        "    raise Exception(\"Only 'tensorflow' is supported as backend\")\n",
        "\n",
        "\n",
        "class BilinearInterpolation(Layer):\n",
        "    \"\"\"Performs bilinear interpolation as a keras layer\n",
        "    References\n",
        "    ----------\n",
        "    [1]  Spatial Transformer Networks, Max Jaderberg, et al.\n",
        "    [2]  https://github.com/skaae/transformer_network\n",
        "    [3]  https://github.com/EderSantana/seya\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, output_size, **kwargs):\n",
        "        self.output_size = output_size\n",
        "        super(BilinearInterpolation, self).__init__(**kwargs)\n",
        "\n",
        "    def get_config(self):\n",
        "        return {\n",
        "            'output_size': self.output_size,\n",
        "        }\n",
        "\n",
        "    def compute_output_shape(self, input_shapes):\n",
        "        height, width = self.output_size\n",
        "        num_channels = input_shapes[0][-1]\n",
        "        return (None, height, width, num_channels)\n",
        "\n",
        "    def call(self, tensors, mask=None):\n",
        "        X, transformation = tensors\n",
        "        output = self._transform(X, transformation, self.output_size)\n",
        "        return output\n",
        "\n",
        "    def _interpolate(self, image, sampled_grids, output_size):\n",
        "\n",
        "        batch_size = K.shape(image)[0]\n",
        "        height = K.shape(image)[1]\n",
        "        width = K.shape(image)[2]\n",
        "        num_channels = K.shape(image)[3]\n",
        "\n",
        "        x = K.cast(K.flatten(sampled_grids[:, 0:1, :]), dtype='float32')\n",
        "        y = K.cast(K.flatten(sampled_grids[:, 1:2, :]), dtype='float32')\n",
        "\n",
        "        x = .5 * (x + 1.0) * K.cast(width, dtype='float32')\n",
        "        y = .5 * (y + 1.0) * K.cast(height, dtype='float32')\n",
        "\n",
        "        x0 = K.cast(x, 'int32')\n",
        "        x1 = x0 + 1\n",
        "        y0 = K.cast(y, 'int32')\n",
        "        y1 = y0 + 1\n",
        "\n",
        "        max_x = int(K.int_shape(image)[2] - 1)\n",
        "        max_y = int(K.int_shape(image)[1] - 1)\n",
        "\n",
        "        x0 = K.clip(x0, 0, max_x)\n",
        "        x1 = K.clip(x1, 0, max_x)\n",
        "        y0 = K.clip(y0, 0, max_y)\n",
        "        y1 = K.clip(y1, 0, max_y)\n",
        "\n",
        "        pixels_batch = K.arange(0, batch_size) * (height * width)\n",
        "        pixels_batch = K.expand_dims(pixels_batch, axis=-1)\n",
        "        flat_output_size = output_size[0] * output_size[1]\n",
        "        base = K.repeat_elements(pixels_batch, flat_output_size, axis=1)\n",
        "        base = K.flatten(base)\n",
        "\n",
        "        # base_y0 = base + (y0 * width)\n",
        "        base_y0 = y0 * width\n",
        "        base_y0 = base + base_y0\n",
        "        # base_y1 = base + (y1 * width)\n",
        "        base_y1 = y1 * width\n",
        "        base_y1 = base_y1 + base\n",
        "\n",
        "        indices_a = base_y0 + x0\n",
        "        indices_b = base_y1 + x0\n",
        "        indices_c = base_y0 + x1\n",
        "        indices_d = base_y1 + x1\n",
        "\n",
        "        flat_image = K.reshape(image, shape=(-1, num_channels))\n",
        "        flat_image = K.cast(flat_image, dtype='float32')\n",
        "        pixel_values_a = K.gather(flat_image, indices_a)\n",
        "        pixel_values_b = K.gather(flat_image, indices_b)\n",
        "        pixel_values_c = K.gather(flat_image, indices_c)\n",
        "        pixel_values_d = K.gather(flat_image, indices_d)\n",
        "\n",
        "        x0 = K.cast(x0, 'float32')\n",
        "        x1 = K.cast(x1, 'float32')\n",
        "        y0 = K.cast(y0, 'float32')\n",
        "        y1 = K.cast(y1, 'float32')\n",
        "\n",
        "        area_a = K.expand_dims(((x1 - x) * (y1 - y)), 1)\n",
        "        area_b = K.expand_dims(((x1 - x) * (y - y0)), 1)\n",
        "        area_c = K.expand_dims(((x - x0) * (y1 - y)), 1)\n",
        "        area_d = K.expand_dims(((x - x0) * (y - y0)), 1)\n",
        "\n",
        "        values_a = area_a * pixel_values_a\n",
        "        values_b = area_b * pixel_values_b\n",
        "        values_c = area_c * pixel_values_c\n",
        "        values_d = area_d * pixel_values_d\n",
        "        return values_a + values_b + values_c + values_d\n",
        "\n",
        "    def _make_regular_grids(self, batch_size, height, width):\n",
        "        # making a single regular grid\n",
        "        x_linspace = K_linspace(-1., 1., width)\n",
        "        y_linspace = K_linspace(-1., 1., height)\n",
        "        x_coordinates, y_coordinates = K_meshgrid(x_linspace, y_linspace)\n",
        "        x_coordinates = K.flatten(x_coordinates)\n",
        "        y_coordinates = K.flatten(y_coordinates)\n",
        "        ones = K.ones_like(x_coordinates)\n",
        "        grid = K.concatenate([x_coordinates, y_coordinates, ones], 0)\n",
        "\n",
        "        # repeating grids for each batch\n",
        "        grid = K.flatten(grid)\n",
        "        grids = K.tile(grid, K.stack([batch_size]))\n",
        "        return K.reshape(grids, (batch_size, 3, height * width))\n",
        "\n",
        "    def _transform(self, X, affine_transformation, output_size):\n",
        "        batch_size, num_channels = K.shape(X)[0], K.shape(X)[3]\n",
        "        transformations = K.reshape(affine_transformation,\n",
        "                                    shape=(batch_size, 2, 3))\n",
        "        # transformations = K.cast(affine_transformation[:, 0:2, :], 'float32')\n",
        "        regular_grids = self._make_regular_grids(batch_size, *output_size)\n",
        "        sampled_grids = K.batch_dot(transformations, regular_grids)\n",
        "        interpolated_image = self._interpolate(X, sampled_grids, output_size)\n",
        "        new_shape = (batch_size, output_size[0], output_size[1], num_channels)\n",
        "        interpolated_image = K.reshape(interpolated_image, new_shape)\n",
        "        return interpolated_image\n"
      ],
      "metadata": {
        "id": "o55SDhmLK2WZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data"
      ],
      "metadata": {
        "id": "Io9RygNDy3HL"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yb_Sj49PJLsZ"
      },
      "source": [
        "This part of the code takes the hourly Z500 data and computes the mean and standard deviation for normalization \n",
        "\n",
        "It takes each netCDF file as one entry to a file list to facilitate memory optimization \n",
        "\n",
        "In this [paper](https://gmd.copernicus.org/preprints/gmd-2021-71/) year 1979-2017 is taken together, where 1979-2016 is used as training and 2017 as validation. \n",
        "\n",
        "In this example, we have changed the validation set slightly. It would not affect the performance. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OqfdOZoLJLsd",
        "outputId": "a5b085e2-6f0a-49db-d749-2b4aa6c5840c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(54110.977, 3355.03)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Getting back the objects:\n",
        "with open('/content/drive/MyDrive/DDWP/z500_mean_sdev.pkl', 'rb') as f:  # Python 3: open(..., 'rb')\n",
        "    M, sdev = pickle.load(f)\n",
        "\n",
        "M, sdev"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rpBRs43wJLsd"
      },
      "outputs": [],
      "source": [
        "fileList_train = []\n",
        "fileList_test=[]\n",
        "for i in range (1979,2018):\n",
        "    fileList_train.append (f'/content/drive/MyDrive/DDWP/geopotential_z500/geopotential_500hPa_' + str(i)+'_5.625deg.nc')\n",
        "\n",
        "for j in range (2018, 2019):\n",
        "    fileList_test.append (f'/content/drive/MyDrive/DDWP/geopotential_z500/geopotential_500hPa_' + str(j)+'_5.625deg.nc')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define and compile model and loss function"
      ],
      "metadata": {
        "id": "VQ0W9tq2yx9z"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ioxITZxJLse"
      },
      "source": [
        "We have defined the model as \"stn\" where \"stn\" includes an U-NET with a spatial transformer module that includes an affine transformation and Biliniear interpolation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EG3yv-oPJLse"
      },
      "outputs": [],
      "source": [
        "## border_mode --> padding\n",
        "\n",
        "def stn(input_shape=(32, 64, 1), sampling_size=(8, 16), num_classes=10):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    conv1 = Conv2D(32, (5, 5), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(32, (5, 5), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D((2,2), padding='same')(conv1)\n",
        "\n",
        "    conv2 = Conv2D(32, (5, 5), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(32, (5, 5), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D((2,2), padding='same')(conv2)\n",
        "\n",
        "    conv3 = Conv2D(32, (5, 5), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(32, (5, 5), activation='relu', padding='same')(conv3)\n",
        "\n",
        "\n",
        "    conv5 = Conv2D(32, (5, 5), activation='relu', padding='same')(conv3)\n",
        "    conv5 = Conv2D(32, (5, 5), activation='relu', padding='same')(conv5)\n",
        "    \n",
        "    locnet = Flatten()(conv5)\n",
        "    locnet = Dense(500)(locnet)\n",
        "    locnet = Activation('relu')(locnet)\n",
        "    locnet = Dense(200)(locnet)\n",
        "    locnet = Activation('relu')(locnet)\n",
        "    locnet = Dense(100)(locnet)\n",
        "    locnet = Activation('relu')(locnet)\n",
        "    locnet = Dense(50)(locnet)\n",
        "    locnet = Activation('relu')(locnet)\n",
        "    weights = get_initial_weights(50)\n",
        "    locnet = Dense(6, weights=weights)(locnet)\n",
        "    x = BilinearInterpolation(sampling_size)([inputs, locnet])\n",
        "\n",
        "\n",
        "    up6 = keras.layers.Concatenate(axis=-1)([Conv2D(32, (2, 2), activation='relu', padding='same')(UpSampling2D(size=(2, 2))(x)), conv2])\n",
        "    conv6 = Conv2D(32, (5, 5), activation='relu', padding='same')(up6)\n",
        "    conv6 = Conv2D(32, (5, 5), activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = keras.layers.Concatenate(axis=-1)([Conv2D(32, (2, 2), activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv6)), conv1])\n",
        "    conv7 = Conv2D(32, (5, 5), activation='relu', padding='same')(up7)\n",
        "    conv7 = Conv2D(32, (5, 5), activation='relu', padding='same')(conv7)\n",
        "\n",
        "    conv10 = Conv2D(1, (5, 5), activation='linear',padding='same')(conv7)\n",
        "    model = Model(inputs=inputs, outputs=conv10)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_baseline(input_shape=(32, 64, 1), sampling_size=(8, 16), num_classes=10):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    conv1 = Conv2D(32, (5, 5), activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(32, (5, 5), activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(32, (5, 5), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(32, (5, 5), activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(32, (5, 5), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(32, (5, 5), activation='relu', padding='same')(conv3)\n",
        "\n",
        "    conv5 = Conv2D(32, (5, 5), activation='relu', padding='same')(conv3)\n",
        "    x = Conv2D(32, (5, 5), activation='relu', padding='same')(conv5)\n",
        "\n",
        "    up6 = keras.layers.Concatenate(axis=-1)([Conv2D(32, (2, 2), activation='relu', padding='same')(UpSampling2D(size=(2, 2))(x)), conv2])\n",
        "    conv6 = Conv2D(32, (5, 5), activation='relu', padding='same')(up6)\n",
        "    conv6 = Conv2D(32, (5, 5), activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up7 = keras.layers.Concatenate(axis=-1)([Conv2D(32, (2, 2),activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv6)), conv1])\n",
        "    conv7 = Conv2D(32, (5, 5), activation='relu', padding='same')(up7)\n",
        "    conv7 = Conv2D(32, (5, 5), activation='relu', padding='same')(conv7)\n",
        "\n",
        "    conv10 = Conv2D(1, (5, 5), activation='linear', padding='same')(conv7)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=conv10)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "GNLBKzG4o2m0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unet_old(input_shape=(32, 64, 1), sampling_size=(8, 16), num_classes=10):\n",
        "  \n",
        "    inputs = Input(shape=(32, 64, 1))\n",
        "\n",
        "    conv1 = Conv2D(32, 3, activation='relu', padding='same')(inputs)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(32, 3, activation='relu', padding='same')(pool1)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(32, 3, activation='relu', padding='same')(pool2)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    locnet = Flatten()(pool3)\n",
        "    locnet = Dense(500)(locnet)\n",
        "    locnet = Activation('relu')(locnet)\n",
        "    locnet = Dense(250)(locnet)\n",
        "    locnet = Activation('relu')(locnet)\n",
        "    locnet = Dense(50)(locnet)\n",
        "    locnet = Activation('relu')(locnet)\n",
        "    weights = get_initial_weights(50)\n",
        "    locnet = Dense(6, weights=weights)(locnet)\n",
        "    x = BilinearInterpolation((8, 16))([inputs, locnet])\n",
        "\n",
        "    conv4 = Conv2D(32, (5, 5), activation='relu', padding='same')(x)\n",
        "    up4 = UpSampling2D(size=(2, 2))(conv4)\n",
        "\n",
        "    conv5 = Conv2D(32, (5, 5), activation='relu', padding='same')(up4)\n",
        "    up5 = UpSampling2D(size=(2, 2))(conv5)\n",
        "\n",
        "    conv6 = Conv2D(1, (5, 5), activation='relu', padding='same')(up5)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=conv6)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "zsO9p6sdLhEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        return K.sqrt(K.mean(K.square(y_pred - y_true))) "
      ],
      "metadata": {
        "id": "dJgmsJp1KJ-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # N is length of training data (number of days)\n",
        "# N = 10\n",
        "# gamma = 0.1\n",
        "# def L1_Loss(y_true, y_pred):\n",
        "#   loss = (1-gamma)*(y_pred - y_true)**2 + (gamma*y_pred)\n",
        "#   return loss/N"
      ],
      "metadata": {
        "id": "IwDNVPa2v83l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# N = 10\n",
        "# gamma = 0.1\n",
        "# def L1_Loss(y_true, y_pred):\n",
        "#   loss = (1-gamma)*(tf.math.reduce_sum((y_pred - y_true)**2)) + (gamma*tf.math.reduce_sum(y_pred))\n",
        "#   return loss/N"
      ],
      "metadata": {
        "id": "AZK6AmEbz0rJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gamma = 0.01\n",
        "def L1_Loss(y_true, y_pred):\n",
        "  term1 = (1 - gamma) * tf.reduce_mean(tf.square(y_pred - y_true))\n",
        "  term2 = gamma * tf.reduce_mean(y_pred)\n",
        "  L1 = term1 + term2\n",
        "\n",
        "  return L1"
      ],
      "metadata": {
        "id": "uf0zZXnakDBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 10\n",
        "gamma = 0.25\n",
        "def L2_Loss(y_true,y_pred):\n",
        "    diff_pred = y_pred[1:] - y_pred[:-1]\n",
        "    diff_true = y_true[1:] - y_true[:-1]\n",
        "\n",
        "    # Define Ψ(pred) and Ψ(true)\n",
        "    psi_pred = tf.math.sigmoid(y_pred)\n",
        "    psi_true = tf.math.sigmoid(y_true)\n",
        "\n",
        "    # Calculate first-order difference of Ψ(pred) and Ψ(true)\n",
        "    psi_diff_pred = psi_pred[1:] - psi_pred[:-1]\n",
        "    psi_diff_true = psi_true[1:] - psi_true[:-1]\n",
        "\n",
        "    # Calculate L2\n",
        "    term1 = (1 - gamma) * tf.reduce_mean(tf.square(psi_pred - psi_true))\n",
        "    term2 = gamma * tf.reduce_mean(tf.square(psi_diff_pred - psi_diff_true))\n",
        "    L2 = term1 + term2\n",
        "\n",
        "    return L2/N"
      ],
      "metadata": {
        "id": "3d5-sDtRNV53"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = tf.ones(100)\n",
        "y = tf.zeros(100)\n",
        "print(L2_Loss(x,y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIdKLu7JOqnZ",
        "outputId": "a976cd62-f402-418b-a560-64300caf2298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(0.0040041036, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = unet_baseline()\n",
        "model.compile(loss=root_mean_squared_error, optimizer='adam')\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "Gjl1mqfvz5ZA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03c0fdb4-7b47-4907-b815-cd9e6c9f1925"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 32, 64, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d_21 (Conv2D)             (None, 32, 64, 32)   832         ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " conv2d_22 (Conv2D)             (None, 32, 64, 32)   25632       ['conv2d_21[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_5 (MaxPooling2D)  (None, 16, 32, 32)  0           ['conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_23 (Conv2D)             (None, 16, 32, 32)   25632       ['max_pooling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_24 (Conv2D)             (None, 16, 32, 32)   25632       ['conv2d_23[0][0]']              \n",
            "                                                                                                  \n",
            " max_pooling2d_6 (MaxPooling2D)  (None, 8, 16, 32)   0           ['conv2d_24[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_25 (Conv2D)             (None, 8, 16, 32)    25632       ['max_pooling2d_6[0][0]']        \n",
            "                                                                                                  \n",
            " conv2d_26 (Conv2D)             (None, 8, 16, 32)    25632       ['conv2d_25[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_27 (Conv2D)             (None, 8, 16, 32)    25632       ['conv2d_26[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_28 (Conv2D)             (None, 8, 16, 32)    25632       ['conv2d_27[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_4 (UpSampling2D)  (None, 16, 32, 32)  0           ['conv2d_28[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_29 (Conv2D)             (None, 16, 32, 32)   4128        ['up_sampling2d_4[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_2 (Concatenate)    (None, 16, 32, 64)   0           ['conv2d_29[0][0]',              \n",
            "                                                                  'conv2d_24[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_30 (Conv2D)             (None, 16, 32, 32)   51232       ['concatenate_2[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_31 (Conv2D)             (None, 16, 32, 32)   25632       ['conv2d_30[0][0]']              \n",
            "                                                                                                  \n",
            " up_sampling2d_5 (UpSampling2D)  (None, 32, 64, 32)  0           ['conv2d_31[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_32 (Conv2D)             (None, 32, 64, 32)   4128        ['up_sampling2d_5[0][0]']        \n",
            "                                                                                                  \n",
            " concatenate_3 (Concatenate)    (None, 32, 64, 64)   0           ['conv2d_32[0][0]',              \n",
            "                                                                  'conv2d_22[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_33 (Conv2D)             (None, 32, 64, 32)   51232       ['concatenate_3[0][0]']          \n",
            "                                                                                                  \n",
            " conv2d_34 (Conv2D)             (None, 32, 64, 32)   25632       ['conv2d_33[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_35 (Conv2D)             (None, 32, 64, 1)    801         ['conv2d_34[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 343,041\n",
            "Trainable params: 343,041\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O20z_Bs5JLse",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20804a89-5b64-4775-cef8-96f1911c99be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 32, 64, 1)]  0           []                               \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)                (None, 32, 64, 32)   320         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " max_pooling2d (MaxPooling2D)   (None, 16, 32, 32)   0           ['conv2d[0][0]']                 \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 16, 32, 32)   9248        ['max_pooling2d[0][0]']          \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 8, 16, 32)   0           ['conv2d_1[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 8, 16, 32)    9248        ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 4, 8, 32)    0           ['conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 1024)         0           ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 500)          512500      ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            " activation (Activation)        (None, 500)          0           ['dense[0][0]']                  \n",
            "                                                                                                  \n",
            " dense_1 (Dense)                (None, 250)          125250      ['activation[0][0]']             \n",
            "                                                                                                  \n",
            " activation_1 (Activation)      (None, 250)          0           ['dense_1[0][0]']                \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape (TFOpLambda  (4,)                0           ['input_1[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 50)           12550       ['activation_1[0][0]']           \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem (Slic  ()                  0           ['tf.compat.v1.shape[0][0]']     \n",
            " ingOpLambda)                                                                                     \n",
            "                                                                                                  \n",
            " activation_2 (Activation)      (None, 50)           0           ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            " tf.stack (TFOpLambda)          (1,)                 0           ['tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 6)            306         ['activation_2[0][0]']           \n",
            "                                                                                                  \n",
            " tf.tile (TFOpLambda)           (None,)              0           ['tf.stack[0][0]']               \n",
            "                                                                                                  \n",
            " tf.reshape (TFOpLambda)        (None, 2, 3)         0           ['dense_3[0][0]',                \n",
            "                                                                  'tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " tf.reshape_1 (TFOpLambda)      (None, 3, 128)       0           ['tf.tile[0][0]',                \n",
            "                                                                  'tf.__operators__.getitem[0][0]'\n",
            "                                                                 ]                                \n",
            "                                                                                                  \n",
            " tf.linalg.matmul (TFOpLambda)  (None, 2, 128)       0           ['tf.reshape[0][0]',             \n",
            "                                                                  'tf.reshape_1[0][0]']           \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_6 (Sl  (None, 1, 128)      0           ['tf.linalg.matmul[0][0]']       \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_7 (Sl  (None, 1, 128)      0           ['tf.linalg.matmul[0][0]']       \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.reshape_2 (TFOpLambda)      (None,)              0           ['tf.__operators__.getitem_6[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.reshape_3 (TFOpLambda)      (None,)              0           ['tf.__operators__.getitem_7[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.cast (TFOpLambda)           (None,)              0           ['tf.reshape_2[0][0]']           \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_5 (TFOpLamb  (4,)                0           ['input_1[0][0]']                \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.cast_1 (TFOpLambda)         (None,)              0           ['tf.reshape_3[0][0]']           \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_4 (TFOpLamb  (4,)                0           ['input_1[0][0]']                \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_3 (TFOpLamb  (4,)                0           ['input_1[0][0]']                \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOpLamb  (None,)             0           ['tf.cast[0][0]']                \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_4 (Sl  ()                  0           ['tf.compat.v1.shape_5[0][0]']   \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.add_1 (TFOpLa  (None,)             0           ['tf.cast_1[0][0]']              \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_3 (Sl  ()                  0           ['tf.compat.v1.shape_4[0][0]']   \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_2 (Sl  ()                  0           ['tf.compat.v1.shape_3[0][0]']   \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.math.multiply (TFOpLambda)  (None,)              0           ['tf.__operators__.add[0][0]']   \n",
            "                                                                                                  \n",
            " tf.cast_2 (TFOpLambda)         ()                   0           ['tf.__operators__.getitem_4[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_2 (TFOpLambda  (None,)             0           ['tf.__operators__.add_1[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.cast_3 (TFOpLambda)         ()                   0           ['tf.__operators__.getitem_3[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.range (TFOpLambda)          (None,)              0           ['tf.__operators__.getitem_2[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_4 (TFOpLambda  ()                  0           ['tf.__operators__.getitem_3[0][0\n",
            " )                                                               ]',                              \n",
            "                                                                  'tf.__operators__.getitem_4[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.math.multiply_1 (TFOpLambda  (None,)             0           ['tf.math.multiply[0][0]',       \n",
            " )                                                                'tf.cast_2[0][0]']              \n",
            "                                                                                                  \n",
            " tf.math.multiply_3 (TFOpLambda  (None,)             0           ['tf.math.multiply_2[0][0]',     \n",
            " )                                                                'tf.cast_3[0][0]']              \n",
            "                                                                                                  \n",
            " tf.math.multiply_5 (TFOpLambda  (None,)             0           ['tf.range[0][0]',               \n",
            " )                                                                'tf.math.multiply_4[0][0]']     \n",
            "                                                                                                  \n",
            " tf.cast_4 (TFOpLambda)         (None,)              0           ['tf.math.multiply_1[0][0]']     \n",
            "                                                                                                  \n",
            " tf.cast_5 (TFOpLambda)         (None,)              0           ['tf.math.multiply_3[0][0]']     \n",
            "                                                                                                  \n",
            " tf.expand_dims (TFOpLambda)    (None, 1)            0           ['tf.math.multiply_5[0][0]']     \n",
            "                                                                                                  \n",
            " tf.__operators__.add_2 (TFOpLa  (None,)             0           ['tf.cast_4[0][0]']              \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.__operators__.add_3 (TFOpLa  (None,)             0           ['tf.cast_5[0][0]']              \n",
            " mbda)                                                                                            \n",
            "                                                                                                  \n",
            " tf.split (TFOpLambda)          [(None, 1)]          0           ['tf.expand_dims[0][0]']         \n",
            "                                                                                                  \n",
            " tf.clip_by_value_1 (TFOpLambda  (None,)             0           ['tf.__operators__.add_2[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.clip_by_value_3 (TFOpLambda  (None,)             0           ['tf.__operators__.add_3[0][0]'] \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_6 (TFOpLamb  (4,)                0           ['input_1[0][0]']                \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.concat (TFOpLambda)         (None, 128)          0           ['tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]',               \n",
            "                                                                  'tf.split[0][0]']               \n",
            "                                                                                                  \n",
            " tf.clip_by_value_2 (TFOpLambda  (None,)             0           ['tf.cast_5[0][0]']              \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " tf.cast_8 (TFOpLambda)         (None,)              0           ['tf.clip_by_value_1[0][0]']     \n",
            "                                                                                                  \n",
            " tf.cast_10 (TFOpLambda)        (None,)              0           ['tf.clip_by_value_3[0][0]']     \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_5 (Sl  ()                  0           ['tf.compat.v1.shape_6[0][0]']   \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.reshape_4 (TFOpLambda)      (None,)              0           ['tf.concat[0][0]']              \n",
            "                                                                                                  \n",
            " tf.math.multiply_6 (TFOpLambda  (None,)             0           ['tf.clip_by_value_2[0][0]',     \n",
            " )                                                                'tf.__operators__.getitem_4[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.clip_by_value (TFOpLambda)  (None,)              0           ['tf.cast_4[0][0]']              \n",
            "                                                                                                  \n",
            " tf.cast_9 (TFOpLambda)         (None,)              0           ['tf.clip_by_value_2[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.multiply_7 (TFOpLambda  (None,)             0           ['tf.clip_by_value_3[0][0]',     \n",
            " )                                                                'tf.__operators__.getitem_4[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.math.subtract (TFOpLambda)  (None,)              0           ['tf.cast_8[0][0]',              \n",
            "                                                                  'tf.math.multiply_1[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.subtract_1 (TFOpLambda  (None,)             0           ['tf.cast_10[0][0]',             \n",
            " )                                                                'tf.math.multiply_3[0][0]']     \n",
            "                                                                                                  \n",
            " tf.reshape_5 (TFOpLambda)      (None, 1)            0           ['input_1[0][0]',                \n",
            "                                                                  'tf.__operators__.getitem_5[0][0\n",
            "                                                                 ]']                              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_4 (TFOpLa  (None,)             0           ['tf.reshape_4[0][0]',           \n",
            " mbda)                                                            'tf.math.multiply_6[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.subtract_2 (TFOpLambda  (None,)             0           ['tf.cast_8[0][0]',              \n",
            " )                                                                'tf.math.multiply_1[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.subtract_3 (TFOpLambda  (None,)             0           ['tf.math.multiply_3[0][0]',     \n",
            " )                                                                'tf.cast_9[0][0]']              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_5 (TFOpLa  (None,)             0           ['tf.math.multiply_7[0][0]',     \n",
            " mbda)                                                            'tf.reshape_4[0][0]']           \n",
            "                                                                                                  \n",
            " tf.cast_7 (TFOpLambda)         (None,)              0           ['tf.clip_by_value[0][0]']       \n",
            "                                                                                                  \n",
            " tf.math.multiply_8 (TFOpLambda  (None,)             0           ['tf.math.subtract[0][0]',       \n",
            " )                                                                'tf.math.subtract_1[0][0]']     \n",
            "                                                                                                  \n",
            " tf.cast_6 (TFOpLambda)         (None, 1)            0           ['tf.reshape_5[0][0]']           \n",
            "                                                                                                  \n",
            " tf.__operators__.add_6 (TFOpLa  (None,)             0           ['tf.__operators__.add_4[0][0]', \n",
            " mbda)                                                            'tf.clip_by_value[0][0]']       \n",
            "                                                                                                  \n",
            " tf.math.multiply_9 (TFOpLambda  (None,)             0           ['tf.math.subtract_2[0][0]',     \n",
            " )                                                                'tf.math.subtract_3[0][0]']     \n",
            "                                                                                                  \n",
            " tf.__operators__.add_7 (TFOpLa  (None,)             0           ['tf.__operators__.add_5[0][0]', \n",
            " mbda)                                                            'tf.clip_by_value[0][0]']       \n",
            "                                                                                                  \n",
            " tf.math.subtract_4 (TFOpLambda  (None,)             0           ['tf.math.multiply_1[0][0]',     \n",
            " )                                                                'tf.cast_7[0][0]']              \n",
            "                                                                                                  \n",
            " tf.math.subtract_5 (TFOpLambda  (None,)             0           ['tf.cast_10[0][0]',             \n",
            " )                                                                'tf.math.multiply_3[0][0]']     \n",
            "                                                                                                  \n",
            " tf.expand_dims_1 (TFOpLambda)  (None, 1)            0           ['tf.math.multiply_8[0][0]']     \n",
            "                                                                                                  \n",
            " tf.compat.v1.gather (TFOpLambd  (None, 1)           0           ['tf.cast_6[0][0]',              \n",
            " a)                                                               'tf.__operators__.add_6[0][0]'] \n",
            "                                                                                                  \n",
            " tf.expand_dims_2 (TFOpLambda)  (None, 1)            0           ['tf.math.multiply_9[0][0]']     \n",
            "                                                                                                  \n",
            " tf.compat.v1.gather_1 (TFOpLam  (None, 1)           0           ['tf.cast_6[0][0]',              \n",
            " bda)                                                             'tf.__operators__.add_7[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.multiply_10 (TFOpLambd  (None,)             0           ['tf.math.subtract_4[0][0]',     \n",
            " a)                                                               'tf.math.subtract_5[0][0]']     \n",
            "                                                                                                  \n",
            " tf.__operators__.add_8 (TFOpLa  (None,)             0           ['tf.__operators__.add_4[0][0]', \n",
            " mbda)                                                            'tf.clip_by_value_1[0][0]']     \n",
            "                                                                                                  \n",
            " tf.math.subtract_6 (TFOpLambda  (None,)             0           ['tf.math.multiply_1[0][0]',     \n",
            " )                                                                'tf.cast_7[0][0]']              \n",
            "                                                                                                  \n",
            " tf.math.subtract_7 (TFOpLambda  (None,)             0           ['tf.math.multiply_3[0][0]',     \n",
            " )                                                                'tf.cast_9[0][0]']              \n",
            "                                                                                                  \n",
            " tf.math.multiply_12 (TFOpLambd  (None, 1)           0           ['tf.expand_dims_1[0][0]',       \n",
            " a)                                                               'tf.compat.v1.gather[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_13 (TFOpLambd  (None, 1)           0           ['tf.expand_dims_2[0][0]',       \n",
            " a)                                                               'tf.compat.v1.gather_1[0][0]']  \n",
            "                                                                                                  \n",
            " tf.expand_dims_3 (TFOpLambda)  (None, 1)            0           ['tf.math.multiply_10[0][0]']    \n",
            "                                                                                                  \n",
            " tf.compat.v1.gather_2 (TFOpLam  (None, 1)           0           ['tf.cast_6[0][0]',              \n",
            " bda)                                                             'tf.__operators__.add_8[0][0]'] \n",
            "                                                                                                  \n",
            " tf.math.multiply_11 (TFOpLambd  (None,)             0           ['tf.math.subtract_6[0][0]',     \n",
            " a)                                                               'tf.math.subtract_7[0][0]']     \n",
            "                                                                                                  \n",
            " tf.__operators__.add_9 (TFOpLa  (None,)             0           ['tf.__operators__.add_5[0][0]', \n",
            " mbda)                                                            'tf.clip_by_value_1[0][0]']     \n",
            "                                                                                                  \n",
            " tf.__operators__.add_10 (TFOpL  (None, 1)           0           ['tf.math.multiply_12[0][0]',    \n",
            " ambda)                                                           'tf.math.multiply_13[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_14 (TFOpLambd  (None, 1)           0           ['tf.expand_dims_3[0][0]',       \n",
            " a)                                                               'tf.compat.v1.gather_2[0][0]']  \n",
            "                                                                                                  \n",
            " tf.expand_dims_4 (TFOpLambda)  (None, 1)            0           ['tf.math.multiply_11[0][0]']    \n",
            "                                                                                                  \n",
            " tf.compat.v1.gather_3 (TFOpLam  (None, 1)           0           ['tf.cast_6[0][0]',              \n",
            " bda)                                                             'tf.__operators__.add_9[0][0]'] \n",
            "                                                                                                  \n",
            " tf.__operators__.add_11 (TFOpL  (None, 1)           0           ['tf.__operators__.add_10[0][0]',\n",
            " ambda)                                                           'tf.math.multiply_14[0][0]']    \n",
            "                                                                                                  \n",
            " tf.math.multiply_15 (TFOpLambd  (None, 1)           0           ['tf.expand_dims_4[0][0]',       \n",
            " a)                                                               'tf.compat.v1.gather_3[0][0]']  \n",
            "                                                                                                  \n",
            " tf.compat.v1.shape_1 (TFOpLamb  (4,)                0           ['input_1[0][0]']                \n",
            " da)                                                                                              \n",
            "                                                                                                  \n",
            " tf.__operators__.add_12 (TFOpL  (None, 1)           0           ['tf.__operators__.add_11[0][0]',\n",
            " ambda)                                                           'tf.math.multiply_15[0][0]']    \n",
            "                                                                                                  \n",
            " tf.__operators__.getitem_1 (Sl  ()                  0           ['tf.compat.v1.shape_1[0][0]']   \n",
            " icingOpLambda)                                                                                   \n",
            "                                                                                                  \n",
            " tf.reshape_6 (TFOpLambda)      (None, 8, 16, 1)     0           ['tf.__operators__.add_12[0][0]',\n",
            "                                                                  'tf.__operators__.getitem[0][0]'\n",
            "                                                                 , 'tf.__operators__.getitem_1[0][\n",
            "                                                                 0]']                             \n",
            "                                                                                                  \n",
            " conv2d_3 (Conv2D)              (None, 8, 16, 32)    832         ['tf.reshape_6[0][0]']           \n",
            "                                                                                                  \n",
            " up_sampling2d (UpSampling2D)   (None, 16, 32, 32)   0           ['conv2d_3[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_4 (Conv2D)              (None, 16, 32, 32)   25632       ['up_sampling2d[0][0]']          \n",
            "                                                                                                  \n",
            " up_sampling2d_1 (UpSampling2D)  (None, 32, 64, 32)  0           ['conv2d_4[0][0]']               \n",
            "                                                                                                  \n",
            " conv2d_5 (Conv2D)              (None, 32, 64, 1)    801         ['up_sampling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 696,687\n",
            "Trainable params: 696,687\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = unet_old()\n",
        "model.compile(loss=L2_Loss, optimizer='adam')\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk3tU5ARJLsf"
      },
      "source": [
        "Here, batch_size, and num_epochs have undergone HPO. Change variable \"lead\" for different \"x\" in U-STNx. Refer to [paper](https://gmd.copernicus.org/preprints/gmd-2021-71/) for details. For each value of lead a different weights file (including biases) would be saved. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train Loop"
      ],
      "metadata": {
        "id": "6xiqF5h3ynRL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2EHobgWJLsf",
        "outputId": "e949e1b5-3d1d-4418-a8d5-723e341969b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******************** counter ******************** COUNT = 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "846/846 [==============================] - ETA: 0s - loss: 0.1083\n",
            "Epoch 1: val_loss improved from inf to 0.07922, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "846/846 [==============================] - 30s 11ms/step - loss: 0.1083 - val_loss: 0.0792\n",
            "Epoch 2/6\n",
            "841/846 [============================>.] - ETA: 0s - loss: 0.0691\n",
            "Epoch 2: val_loss improved from 0.07922 to 0.07579, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "846/846 [==============================] - 9s 10ms/step - loss: 0.0691 - val_loss: 0.0758\n",
            "Epoch 3/6\n",
            "846/846 [==============================] - ETA: 0s - loss: 0.0595\n",
            "Epoch 3: val_loss improved from 0.07579 to 0.07410, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "846/846 [==============================] - 10s 11ms/step - loss: 0.0595 - val_loss: 0.0741\n",
            "Epoch 4/6\n",
            "842/846 [============================>.] - ETA: 0s - loss: 0.0537\n",
            "Epoch 4: val_loss improved from 0.07410 to 0.07263, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "846/846 [==============================] - 10s 12ms/step - loss: 0.0537 - val_loss: 0.0726\n",
            "Epoch 5/6\n",
            "841/846 [============================>.] - ETA: 0s - loss: 0.0500\n",
            "Epoch 5: val_loss improved from 0.07263 to 0.07229, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "846/846 [==============================] - 9s 10ms/step - loss: 0.0500 - val_loss: 0.0723\n",
            "Epoch 6/6\n",
            "843/846 [============================>.] - ETA: 0s - loss: 0.0472\n",
            "Epoch 6: val_loss did not improve from 0.07229\n",
            "846/846 [==============================] - 9s 10ms/step - loss: 0.0472 - val_loss: 0.0728\n",
            "******************** counter ******************** COUNT = 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "849/849 [==============================] - ETA: 0s - loss: 0.0609\n",
            "Epoch 1: val_loss improved from inf to 0.06801, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "849/849 [==============================] - 16s 11ms/step - loss: 0.0609 - val_loss: 0.0680\n",
            "Epoch 2/6\n",
            "847/849 [============================>.] - ETA: 0s - loss: 0.0495\n",
            "Epoch 2: val_loss improved from 0.06801 to 0.06663, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "849/849 [==============================] - 12s 14ms/step - loss: 0.0495 - val_loss: 0.0666\n",
            "Epoch 3/6\n",
            "848/849 [============================>.] - ETA: 0s - loss: 0.0459\n",
            "Epoch 3: val_loss improved from 0.06663 to 0.06551, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "849/849 [==============================] - 10s 12ms/step - loss: 0.0459 - val_loss: 0.0655\n",
            "Epoch 4/6\n",
            "849/849 [==============================] - ETA: 0s - loss: 0.0437\n",
            "Epoch 4: val_loss improved from 0.06551 to 0.06464, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "849/849 [==============================] - 9s 11ms/step - loss: 0.0437 - val_loss: 0.0646\n",
            "Epoch 5/6\n",
            "848/849 [============================>.] - ETA: 0s - loss: 0.0418\n",
            "Epoch 5: val_loss did not improve from 0.06464\n",
            "849/849 [==============================] - 9s 11ms/step - loss: 0.0418 - val_loss: 0.0675\n",
            "Epoch 6/6\n",
            "846/849 [============================>.] - ETA: 0s - loss: 0.0406\n",
            "Epoch 6: val_loss did not improve from 0.06464\n",
            "849/849 [==============================] - 9s 10ms/step - loss: 0.0406 - val_loss: 0.0721\n",
            "******************** counter ******************** COUNT = 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "843/846 [============================>.] - ETA: 0s - loss: 0.0565\n",
            "Epoch 1: val_loss improved from inf to 0.06492, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "846/846 [==============================] - 15s 10ms/step - loss: 0.0565 - val_loss: 0.0649\n",
            "Epoch 2/6\n",
            "842/846 [============================>.] - ETA: 0s - loss: 0.0469\n",
            "Epoch 2: val_loss did not improve from 0.06492\n",
            "846/846 [==============================] - 9s 10ms/step - loss: 0.0469 - val_loss: 0.0674\n",
            "Epoch 3/6\n",
            "846/846 [==============================] - ETA: 0s - loss: 0.0437\n",
            "Epoch 3: val_loss did not improve from 0.06492\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0437 - val_loss: 0.0655\n",
            "Epoch 4/6\n",
            "846/846 [==============================] - ETA: 0s - loss: 0.0417\n",
            "Epoch 4: val_loss did not improve from 0.06492\n",
            "846/846 [==============================] - 9s 10ms/step - loss: 0.0417 - val_loss: 0.0719\n",
            "Epoch 5/6\n",
            "845/846 [============================>.] - ETA: 0s - loss: 0.0404\n",
            "Epoch 5: val_loss did not improve from 0.06492\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0404 - val_loss: 0.0667\n",
            "Epoch 6/6\n",
            "844/846 [============================>.] - ETA: 0s - loss: 0.0392\n",
            "Epoch 6: val_loss did not improve from 0.06492\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0392 - val_loss: 0.0672\n",
            "******************** counter ******************** COUNT = 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "842/846 [============================>.] - ETA: 0s - loss: 0.0550\n",
            "Epoch 1: val_loss improved from inf to 0.06106, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "846/846 [==============================] - 15s 10ms/step - loss: 0.0550 - val_loss: 0.0611\n",
            "Epoch 2/6\n",
            "845/846 [============================>.] - ETA: 0s - loss: 0.0456\n",
            "Epoch 2: val_loss improved from 0.06106 to 0.05953, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "846/846 [==============================] - 9s 11ms/step - loss: 0.0456 - val_loss: 0.0595\n",
            "Epoch 3/6\n",
            "846/846 [==============================] - ETA: 0s - loss: 0.0424\n",
            "Epoch 3: val_loss did not improve from 0.05953\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0424 - val_loss: 0.0658\n",
            "Epoch 4/6\n",
            "844/846 [============================>.] - ETA: 0s - loss: 0.0406\n",
            "Epoch 4: val_loss did not improve from 0.05953\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0406 - val_loss: 0.0629\n",
            "Epoch 5/6\n",
            "842/846 [============================>.] - ETA: 0s - loss: 0.0390\n",
            "Epoch 5: val_loss did not improve from 0.05953\n",
            "846/846 [==============================] - 9s 10ms/step - loss: 0.0390 - val_loss: 0.0620\n",
            "Epoch 6/6\n",
            "844/846 [============================>.] - ETA: 0s - loss: 0.0380\n",
            "Epoch 6: val_loss did not improve from 0.05953\n",
            "846/846 [==============================] - 8s 9ms/step - loss: 0.0380 - val_loss: 0.0618\n",
            "******************** counter ******************** COUNT = 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "842/846 [============================>.] - ETA: 0s - loss: 0.0535\n",
            "Epoch 1: val_loss improved from inf to 0.06635, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "846/846 [==============================] - 14s 11ms/step - loss: 0.0534 - val_loss: 0.0664\n",
            "Epoch 2/6\n",
            "846/846 [==============================] - ETA: 0s - loss: 0.0451\n",
            "Epoch 2: val_loss did not improve from 0.06635\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0451 - val_loss: 0.0682\n",
            "Epoch 3/6\n",
            "841/846 [============================>.] - ETA: 0s - loss: 0.0417\n",
            "Epoch 3: val_loss did not improve from 0.06635\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0417 - val_loss: 0.0702\n",
            "Epoch 4/6\n",
            "846/846 [==============================] - ETA: 0s - loss: 0.0402\n",
            "Epoch 4: val_loss did not improve from 0.06635\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0402 - val_loss: 0.0692\n",
            "Epoch 5/6\n",
            "843/846 [============================>.] - ETA: 0s - loss: 0.0389\n",
            "Epoch 5: val_loss did not improve from 0.06635\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0389 - val_loss: 0.0696\n",
            "Epoch 6/6\n",
            "843/846 [============================>.] - ETA: 0s - loss: 0.0379\n",
            "Epoch 6: val_loss did not improve from 0.06635\n",
            "846/846 [==============================] - 9s 10ms/step - loss: 0.0379 - val_loss: 0.0692\n",
            "******************** counter ******************** COUNT = 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "846/849 [============================>.] - ETA: 0s - loss: 0.0529\n",
            "Epoch 1: val_loss improved from inf to 0.06526, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "849/849 [==============================] - 14s 11ms/step - loss: 0.0529 - val_loss: 0.0653\n",
            "Epoch 2/6\n",
            "847/849 [============================>.] - ETA: 0s - loss: 0.0442\n",
            "Epoch 2: val_loss improved from 0.06526 to 0.06468, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "849/849 [==============================] - 9s 11ms/step - loss: 0.0442 - val_loss: 0.0647\n",
            "Epoch 3/6\n",
            "847/849 [============================>.] - ETA: 0s - loss: 0.0414\n",
            "Epoch 3: val_loss improved from 0.06468 to 0.06394, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "849/849 [==============================] - 9s 11ms/step - loss: 0.0414 - val_loss: 0.0639\n",
            "Epoch 4/6\n",
            "845/849 [============================>.] - ETA: 0s - loss: 0.0393\n",
            "Epoch 4: val_loss did not improve from 0.06394\n",
            "849/849 [==============================] - 9s 10ms/step - loss: 0.0393 - val_loss: 0.0640\n",
            "Epoch 5/6\n",
            "849/849 [==============================] - ETA: 0s - loss: 0.0384\n",
            "Epoch 5: val_loss did not improve from 0.06394\n",
            "849/849 [==============================] - 8s 10ms/step - loss: 0.0384 - val_loss: 0.0665\n",
            "Epoch 6/6\n",
            "849/849 [==============================] - ETA: 0s - loss: 0.0372\n",
            "Epoch 6: val_loss did not improve from 0.06394\n",
            "849/849 [==============================] - 9s 10ms/step - loss: 0.0372 - val_loss: 0.0660\n",
            "******************** counter ******************** COUNT = 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "846/846 [==============================] - ETA: 0s - loss: 0.0521\n",
            "Epoch 1: val_loss improved from inf to 0.05958, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "846/846 [==============================] - 15s 10ms/step - loss: 0.0521 - val_loss: 0.0596\n",
            "Epoch 2/6\n",
            "842/846 [============================>.] - ETA: 0s - loss: 0.0435\n",
            "Epoch 2: val_loss did not improve from 0.05958\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0435 - val_loss: 0.0602\n",
            "Epoch 3/6\n",
            "845/846 [============================>.] - ETA: 0s - loss: 0.0407\n",
            "Epoch 3: val_loss did not improve from 0.05958\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0407 - val_loss: 0.0612\n",
            "Epoch 4/6\n",
            "846/846 [==============================] - ETA: 0s - loss: 0.0390\n",
            "Epoch 4: val_loss did not improve from 0.05958\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0390 - val_loss: 0.0605\n",
            "Epoch 5/6\n",
            "844/846 [============================>.] - ETA: 0s - loss: 0.0384\n",
            "Epoch 5: val_loss did not improve from 0.05958\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0384 - val_loss: 0.0627\n",
            "Epoch 6/6\n",
            "842/846 [============================>.] - ETA: 0s - loss: 0.0369\n",
            "Epoch 6: val_loss did not improve from 0.05958\n",
            "846/846 [==============================] - 8s 9ms/step - loss: 0.0369 - val_loss: 0.0619\n",
            "******************** counter ******************** COUNT = 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "845/846 [============================>.] - ETA: 0s - loss: 0.0512\n",
            "Epoch 1: val_loss improved from inf to 0.06175, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "846/846 [==============================] - 13s 10ms/step - loss: 0.0512 - val_loss: 0.0618\n",
            "Epoch 2/6\n",
            "843/846 [============================>.] - ETA: 0s - loss: 0.0433\n",
            "Epoch 2: val_loss did not improve from 0.06175\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0433 - val_loss: 0.0634\n",
            "Epoch 3/6\n",
            "844/846 [============================>.] - ETA: 0s - loss: 0.0407\n",
            "Epoch 3: val_loss did not improve from 0.06175\n",
            "846/846 [==============================] - 9s 10ms/step - loss: 0.0407 - val_loss: 0.0666\n",
            "Epoch 4/6\n",
            "841/846 [============================>.] - ETA: 0s - loss: 0.0384\n",
            "Epoch 4: val_loss did not improve from 0.06175\n",
            "846/846 [==============================] - 8s 9ms/step - loss: 0.0384 - val_loss: 0.0629\n",
            "Epoch 5/6\n",
            "841/846 [============================>.] - ETA: 0s - loss: 0.0379\n",
            "Epoch 5: val_loss did not improve from 0.06175\n",
            "846/846 [==============================] - 9s 10ms/step - loss: 0.0379 - val_loss: 0.0638\n",
            "Epoch 6/6\n",
            "846/846 [==============================] - ETA: 0s - loss: 0.0364\n",
            "Epoch 6: val_loss did not improve from 0.06175\n",
            "846/846 [==============================] - 9s 10ms/step - loss: 0.0364 - val_loss: 0.0637\n",
            "******************** counter ******************** COUNT = 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "844/846 [============================>.] - ETA: 0s - loss: 0.0521\n",
            "Epoch 1: val_loss improved from inf to 0.05704, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "846/846 [==============================] - 14s 11ms/step - loss: 0.0520 - val_loss: 0.0570\n",
            "Epoch 2/6\n",
            "841/846 [============================>.] - ETA: 0s - loss: 0.0429\n",
            "Epoch 2: val_loss did not improve from 0.05704\n",
            "846/846 [==============================] - 8s 9ms/step - loss: 0.0429 - val_loss: 0.0592\n",
            "Epoch 3/6\n",
            "844/846 [============================>.] - ETA: 0s - loss: 0.0405\n",
            "Epoch 3: val_loss did not improve from 0.05704\n",
            "846/846 [==============================] - 9s 11ms/step - loss: 0.0405 - val_loss: 0.0582\n",
            "Epoch 4/6\n",
            "844/846 [============================>.] - ETA: 0s - loss: 0.0385\n",
            "Epoch 4: val_loss did not improve from 0.05704\n",
            "846/846 [==============================] - 8s 9ms/step - loss: 0.0385 - val_loss: 0.0597\n",
            "Epoch 5/6\n",
            "846/846 [==============================] - ETA: 0s - loss: 0.0378\n",
            "Epoch 5: val_loss did not improve from 0.05704\n",
            "846/846 [==============================] - 9s 10ms/step - loss: 0.0378 - val_loss: 0.0584\n",
            "Epoch 6/6\n",
            "842/846 [============================>.] - ETA: 0s - loss: 0.0363\n",
            "Epoch 6: val_loss did not improve from 0.05704\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0363 - val_loss: 0.0581\n",
            "******************** counter ******************** COUNT = 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "846/849 [============================>.] - ETA: 0s - loss: 0.0509\n",
            "Epoch 1: val_loss improved from inf to 0.05957, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "849/849 [==============================] - 15s 11ms/step - loss: 0.0509 - val_loss: 0.0596\n",
            "Epoch 2/6\n",
            "849/849 [==============================] - ETA: 0s - loss: 0.0428\n",
            "Epoch 2: val_loss did not improve from 0.05957\n",
            "849/849 [==============================] - 9s 10ms/step - loss: 0.0428 - val_loss: 0.0631\n",
            "Epoch 3/6\n",
            "846/849 [============================>.] - ETA: 0s - loss: 0.0399\n",
            "Epoch 3: val_loss did not improve from 0.05957\n",
            "849/849 [==============================] - 9s 10ms/step - loss: 0.0399 - val_loss: 0.0596\n",
            "Epoch 4/6\n",
            "846/849 [============================>.] - ETA: 0s - loss: 0.0384\n",
            "Epoch 4: val_loss did not improve from 0.05957\n",
            "849/849 [==============================] - 9s 11ms/step - loss: 0.0384 - val_loss: 0.0632\n",
            "Epoch 5/6\n",
            "847/849 [============================>.] - ETA: 0s - loss: 0.0369\n",
            "Epoch 5: val_loss did not improve from 0.05957\n",
            "849/849 [==============================] - 8s 10ms/step - loss: 0.0369 - val_loss: 0.0623\n",
            "Epoch 6/6\n",
            "847/849 [============================>.] - ETA: 0s - loss: 0.0360\n",
            "Epoch 6: val_loss did not improve from 0.05957\n",
            "849/849 [==============================] - 9s 11ms/step - loss: 0.0360 - val_loss: 0.0607\n",
            "******************** counter ******************** COUNT = 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "843/846 [============================>.] - ETA: 0s - loss: 0.0502\n",
            "Epoch 1: val_loss improved from inf to 0.06477, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "846/846 [==============================] - 13s 10ms/step - loss: 0.0501 - val_loss: 0.0648\n",
            "Epoch 2/6\n",
            "842/846 [============================>.] - ETA: 0s - loss: 0.0423\n",
            "Epoch 2: val_loss did not improve from 0.06477\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0423 - val_loss: 0.0688\n",
            "Epoch 3/6\n",
            "845/846 [============================>.] - ETA: 0s - loss: 0.0397\n",
            "Epoch 3: val_loss improved from 0.06477 to 0.06464, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "846/846 [==============================] - 9s 10ms/step - loss: 0.0397 - val_loss: 0.0646\n",
            "Epoch 4/6\n",
            "842/846 [============================>.] - ETA: 0s - loss: 0.0379\n",
            "Epoch 4: val_loss did not improve from 0.06464\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0379 - val_loss: 0.0651\n",
            "Epoch 5/6\n",
            "842/846 [============================>.] - ETA: 0s - loss: 0.0368\n",
            "Epoch 5: val_loss improved from 0.06464 to 0.06428, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "846/846 [==============================] - 9s 11ms/step - loss: 0.0368 - val_loss: 0.0643\n",
            "Epoch 6/6\n",
            "844/846 [============================>.] - ETA: 0s - loss: 0.0358\n",
            "Epoch 6: val_loss did not improve from 0.06428\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0358 - val_loss: 0.0651\n",
            "******************** counter ******************** COUNT = 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "843/846 [============================>.] - ETA: 0s - loss: 0.0494\n",
            "Epoch 1: val_loss improved from inf to 0.06096, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "846/846 [==============================] - 14s 10ms/step - loss: 0.0494 - val_loss: 0.0610\n",
            "Epoch 2/6\n",
            "846/846 [==============================] - ETA: 0s - loss: 0.0418\n",
            "Epoch 2: val_loss did not improve from 0.06096\n",
            "846/846 [==============================] - 9s 11ms/step - loss: 0.0418 - val_loss: 0.0627\n",
            "Epoch 3/6\n",
            "845/846 [============================>.] - ETA: 0s - loss: 0.0388\n",
            "Epoch 3: val_loss did not improve from 0.06096\n",
            "846/846 [==============================] - 8s 9ms/step - loss: 0.0388 - val_loss: 0.0627\n",
            "Epoch 4/6\n",
            "846/846 [==============================] - ETA: 0s - loss: 0.0377\n",
            "Epoch 4: val_loss did not improve from 0.06096\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0377 - val_loss: 0.0617\n",
            "Epoch 5/6\n",
            "845/846 [============================>.] - ETA: 0s - loss: 0.0361\n",
            "Epoch 5: val_loss did not improve from 0.06096\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0361 - val_loss: 0.0629\n",
            "Epoch 6/6\n",
            "846/846 [==============================] - ETA: 0s - loss: 0.0355\n",
            "Epoch 6: val_loss did not improve from 0.06096\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0355 - val_loss: 0.0631\n",
            "******************** counter ******************** COUNT = 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "844/846 [============================>.] - ETA: 0s - loss: 0.0507\n",
            "Epoch 1: val_loss improved from inf to 0.06157, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "846/846 [==============================] - 14s 10ms/step - loss: 0.0506 - val_loss: 0.0616\n",
            "Epoch 2/6\n",
            "846/846 [==============================] - ETA: 0s - loss: 0.0425\n",
            "Epoch 2: val_loss improved from 0.06157 to 0.06035, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "846/846 [==============================] - 9s 11ms/step - loss: 0.0425 - val_loss: 0.0604\n",
            "Epoch 3/6\n",
            "844/846 [============================>.] - ETA: 0s - loss: 0.0400\n",
            "Epoch 3: val_loss did not improve from 0.06035\n",
            "846/846 [==============================] - 9s 10ms/step - loss: 0.0400 - val_loss: 0.0614\n",
            "Epoch 4/6\n",
            "846/846 [==============================] - ETA: 0s - loss: 0.0380\n",
            "Epoch 4: val_loss did not improve from 0.06035\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0380 - val_loss: 0.0627\n",
            "Epoch 5/6\n",
            "844/846 [============================>.] - ETA: 0s - loss: 0.0369\n",
            "Epoch 5: val_loss did not improve from 0.06035\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0369 - val_loss: 0.0637\n",
            "Epoch 6/6\n",
            "845/846 [============================>.] - ETA: 0s - loss: 0.0362\n",
            "Epoch 6: val_loss did not improve from 0.06035\n",
            "846/846 [==============================] - 8s 9ms/step - loss: 0.0362 - val_loss: 0.0626\n",
            "******************** counter ******************** COUNT = 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "845/849 [============================>.] - ETA: 0s - loss: 0.0495\n",
            "Epoch 1: val_loss improved from inf to 0.06122, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "849/849 [==============================] - 15s 11ms/step - loss: 0.0495 - val_loss: 0.0612\n",
            "Epoch 2/6\n",
            "847/849 [============================>.] - ETA: 0s - loss: 0.0417\n",
            "Epoch 2: val_loss did not improve from 0.06122\n",
            "849/849 [==============================] - 8s 10ms/step - loss: 0.0417 - val_loss: 0.0663\n",
            "Epoch 3/6\n",
            "848/849 [============================>.] - ETA: 0s - loss: 0.0392\n",
            "Epoch 3: val_loss did not improve from 0.06122\n",
            "849/849 [==============================] - 9s 11ms/step - loss: 0.0392 - val_loss: 0.0642\n",
            "Epoch 4/6\n",
            "849/849 [==============================] - ETA: 0s - loss: 0.0377\n",
            "Epoch 4: val_loss did not improve from 0.06122\n",
            "849/849 [==============================] - 9s 10ms/step - loss: 0.0377 - val_loss: 0.0629\n",
            "Epoch 5/6\n",
            "846/849 [============================>.] - ETA: 0s - loss: 0.0363\n",
            "Epoch 5: val_loss did not improve from 0.06122\n",
            "849/849 [==============================] - 9s 10ms/step - loss: 0.0363 - val_loss: 0.0632\n",
            "Epoch 6/6\n",
            "847/849 [============================>.] - ETA: 0s - loss: 0.0356\n",
            "Epoch 6: val_loss did not improve from 0.06122\n",
            "849/849 [==============================] - 9s 11ms/step - loss: 0.0356 - val_loss: 0.0641\n",
            "******************** counter ******************** COUNT = 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "841/846 [============================>.] - ETA: 0s - loss: 0.0499\n",
            "Epoch 1: val_loss improved from inf to 0.05805, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "846/846 [==============================] - 14s 12ms/step - loss: 0.0498 - val_loss: 0.0580\n",
            "Epoch 2/6\n",
            "842/846 [============================>.] - ETA: 0s - loss: 0.0421\n",
            "Epoch 2: val_loss improved from 0.05805 to 0.05643, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "846/846 [==============================] - 9s 10ms/step - loss: 0.0421 - val_loss: 0.0564\n",
            "Epoch 3/6\n",
            "844/846 [============================>.] - ETA: 0s - loss: 0.0393\n",
            "Epoch 3: val_loss did not improve from 0.05643\n",
            "846/846 [==============================] - 9s 10ms/step - loss: 0.0393 - val_loss: 0.0578\n",
            "Epoch 4/6\n",
            "843/846 [============================>.] - ETA: 0s - loss: 0.0379\n",
            "Epoch 4: val_loss did not improve from 0.05643\n",
            "846/846 [==============================] - 9s 10ms/step - loss: 0.0379 - val_loss: 0.0584\n",
            "Epoch 5/6\n",
            "842/846 [============================>.] - ETA: 0s - loss: 0.0366\n",
            "Epoch 5: val_loss did not improve from 0.05643\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0366 - val_loss: 0.0575\n",
            "Epoch 6/6\n",
            "845/846 [============================>.] - ETA: 0s - loss: 0.0358\n",
            "Epoch 6: val_loss did not improve from 0.05643\n",
            "846/846 [==============================] - 9s 10ms/step - loss: 0.0358 - val_loss: 0.0571\n",
            "******************** counter ******************** COUNT = 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "846/846 [==============================] - ETA: 0s - loss: 0.0489\n",
            "Epoch 1: val_loss improved from inf to 0.05245, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "846/846 [==============================] - 13s 11ms/step - loss: 0.0489 - val_loss: 0.0525\n",
            "Epoch 2/6\n",
            "845/846 [============================>.] - ETA: 0s - loss: 0.0413\n",
            "Epoch 2: val_loss did not improve from 0.05245\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0413 - val_loss: 0.0546\n",
            "Epoch 3/6\n",
            "845/846 [============================>.] - ETA: 0s - loss: 0.0387\n",
            "Epoch 3: val_loss did not improve from 0.05245\n",
            "846/846 [==============================] - 9s 10ms/step - loss: 0.0387 - val_loss: 0.0570\n",
            "Epoch 4/6\n",
            "844/846 [============================>.] - ETA: 0s - loss: 0.0372\n",
            "Epoch 4: val_loss did not improve from 0.05245\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0372 - val_loss: 0.0541\n",
            "Epoch 5/6\n",
            "842/846 [============================>.] - ETA: 0s - loss: 0.0361\n",
            "Epoch 5: val_loss did not improve from 0.05245\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0361 - val_loss: 0.0553\n",
            "Epoch 6/6\n",
            "844/846 [============================>.] - ETA: 0s - loss: 0.0351\n",
            "Epoch 6: val_loss did not improve from 0.05245\n",
            "846/846 [==============================] - 9s 11ms/step - loss: 0.0351 - val_loss: 0.0555\n",
            "******************** counter ******************** COUNT = 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "841/846 [============================>.] - ETA: 0s - loss: 0.0482\n",
            "Epoch 1: val_loss improved from inf to 0.05674, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "846/846 [==============================] - 14s 11ms/step - loss: 0.0482 - val_loss: 0.0567\n",
            "Epoch 2/6\n",
            "843/846 [============================>.] - ETA: 0s - loss: 0.0412\n",
            "Epoch 2: val_loss did not improve from 0.05674\n",
            "846/846 [==============================] - 8s 9ms/step - loss: 0.0412 - val_loss: 0.0573\n",
            "Epoch 3/6\n",
            "846/846 [==============================] - ETA: 0s - loss: 0.0388\n",
            "Epoch 3: val_loss did not improve from 0.05674\n",
            "846/846 [==============================] - 9s 10ms/step - loss: 0.0388 - val_loss: 0.0583\n",
            "Epoch 4/6\n",
            "843/846 [============================>.] - ETA: 0s - loss: 0.0372\n",
            "Epoch 4: val_loss did not improve from 0.05674\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0372 - val_loss: 0.0587\n",
            "Epoch 5/6\n",
            "843/846 [============================>.] - ETA: 0s - loss: 0.0358\n",
            "Epoch 5: val_loss did not improve from 0.05674\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0358 - val_loss: 0.0579\n",
            "Epoch 6/6\n",
            "841/846 [============================>.] - ETA: 0s - loss: 0.0352\n",
            "Epoch 6: val_loss did not improve from 0.05674\n",
            "846/846 [==============================] - 9s 10ms/step - loss: 0.0352 - val_loss: 0.0589\n",
            "******************** counter ******************** COUNT = 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "847/849 [============================>.] - ETA: 0s - loss: 0.0493\n",
            "Epoch 1: val_loss improved from inf to 0.05992, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "849/849 [==============================] - 15s 11ms/step - loss: 0.0493 - val_loss: 0.0599\n",
            "Epoch 2/6\n",
            "846/849 [============================>.] - ETA: 0s - loss: 0.0419\n",
            "Epoch 2: val_loss did not improve from 0.05992\n",
            "849/849 [==============================] - 8s 10ms/step - loss: 0.0419 - val_loss: 0.0614\n",
            "Epoch 3/6\n",
            "848/849 [============================>.] - ETA: 0s - loss: 0.0393\n",
            "Epoch 3: val_loss did not improve from 0.05992\n",
            "849/849 [==============================] - 9s 10ms/step - loss: 0.0393 - val_loss: 0.0606\n",
            "Epoch 4/6\n",
            "849/849 [==============================] - ETA: 0s - loss: 0.0375\n",
            "Epoch 4: val_loss did not improve from 0.05992\n",
            "849/849 [==============================] - 9s 11ms/step - loss: 0.0375 - val_loss: 0.0612\n",
            "Epoch 5/6\n",
            "844/849 [============================>.] - ETA: 0s - loss: 0.0362\n",
            "Epoch 5: val_loss did not improve from 0.05992\n",
            "849/849 [==============================] - 8s 10ms/step - loss: 0.0362 - val_loss: 0.0636\n",
            "Epoch 6/6\n",
            "849/849 [==============================] - ETA: 0s - loss: 0.0357\n",
            "Epoch 6: val_loss did not improve from 0.05992\n",
            "849/849 [==============================] - 9s 11ms/step - loss: 0.0357 - val_loss: 0.0627\n",
            "******************** counter ******************** COUNT = 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "845/846 [============================>.] - ETA: 0s - loss: 0.0492\n",
            "Epoch 1: val_loss improved from inf to 0.05259, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "846/846 [==============================] - 15s 11ms/step - loss: 0.0492 - val_loss: 0.0526\n",
            "Epoch 2/6\n",
            "844/846 [============================>.] - ETA: 0s - loss: 0.0419\n",
            "Epoch 2: val_loss did not improve from 0.05259\n",
            "846/846 [==============================] - 9s 10ms/step - loss: 0.0419 - val_loss: 0.0537\n",
            "Epoch 3/6\n",
            "842/846 [============================>.] - ETA: 0s - loss: 0.0395\n",
            "Epoch 3: val_loss did not improve from 0.05259\n",
            "846/846 [==============================] - 8s 9ms/step - loss: 0.0395 - val_loss: 0.0542\n",
            "Epoch 4/6\n",
            "846/846 [==============================] - ETA: 0s - loss: 0.0376\n",
            "Epoch 4: val_loss did not improve from 0.05259\n",
            "846/846 [==============================] - 9s 11ms/step - loss: 0.0376 - val_loss: 0.0564\n",
            "Epoch 5/6\n",
            "845/846 [============================>.] - ETA: 0s - loss: 0.0367\n",
            "Epoch 5: val_loss did not improve from 0.05259\n",
            "846/846 [==============================] - 8s 9ms/step - loss: 0.0367 - val_loss: 0.0591\n",
            "Epoch 6/6\n",
            "842/846 [============================>.] - ETA: 0s - loss: 0.0356\n",
            "Epoch 6: val_loss did not improve from 0.05259\n",
            "846/846 [==============================] - 9s 10ms/step - loss: 0.0356 - val_loss: 0.0554\n",
            "******************** counter ******************** COUNT = 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "843/846 [============================>.] - ETA: 0s - loss: 0.0476\n",
            "Epoch 1: val_loss improved from inf to 0.05796, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "846/846 [==============================] - 14s 10ms/step - loss: 0.0476 - val_loss: 0.0580\n",
            "Epoch 2/6\n",
            "844/846 [============================>.] - ETA: 0s - loss: 0.0407\n",
            "Epoch 2: val_loss did not improve from 0.05796\n",
            "846/846 [==============================] - 9s 11ms/step - loss: 0.0407 - val_loss: 0.0593\n",
            "Epoch 3/6\n",
            "842/846 [============================>.] - ETA: 0s - loss: 0.0382\n",
            "Epoch 3: val_loss did not improve from 0.05796\n",
            "846/846 [==============================] - 8s 9ms/step - loss: 0.0382 - val_loss: 0.0600\n",
            "Epoch 4/6\n",
            "845/846 [============================>.] - ETA: 0s - loss: 0.0367\n",
            "Epoch 4: val_loss did not improve from 0.05796\n",
            "846/846 [==============================] - 9s 10ms/step - loss: 0.0367 - val_loss: 0.0590\n",
            "Epoch 5/6\n",
            "844/846 [============================>.] - ETA: 0s - loss: 0.0357\n",
            "Epoch 5: val_loss did not improve from 0.05796\n",
            "846/846 [==============================] - 8s 10ms/step - loss: 0.0357 - val_loss: 0.0595\n",
            "Epoch 6/6\n",
            "845/846 [============================>.] - ETA: 0s - loss: 0.0346\n",
            "Epoch 6: val_loss did not improve from 0.05796\n",
            "846/846 [==============================] - 9s 10ms/step - loss: 0.0346 - val_loss: 0.0589\n",
            "******************** counter ******************** COUNT = 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n",
            "844/846 [============================>.] - ETA: 0s - loss: 0.0482\n",
            "Epoch 1: val_loss improved from inf to 0.05486, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "846/846 [==============================] - 15s 10ms/step - loss: 0.0482 - val_loss: 0.0549\n",
            "Epoch 2/6\n",
            "842/846 [============================>.] - ETA: 0s - loss: 0.0412\n",
            "Epoch 2: val_loss did not improve from 0.05486\n",
            "846/846 [==============================] - 9s 10ms/step - loss: 0.0412 - val_loss: 0.0573\n",
            "Epoch 3/6\n",
            "846/846 [==============================] - ETA: 0s - loss: 0.0389\n",
            "Epoch 3: val_loss improved from 0.05486 to 0.05458, saving model to /content/drive/MyDrive/DDWP/persistence_rmse_2.h5\n",
            "846/846 [==============================] - 9s 11ms/step - loss: 0.0389 - val_loss: 0.0546\n",
            "Epoch 4/6\n",
            "842/846 [============================>.] - ETA: 0s - loss: 0.0371\n",
            "Epoch 4: val_loss did not improve from 0.05458\n",
            "846/846 [==============================] - 9s 10ms/step - loss: 0.0371 - val_loss: 0.0547\n",
            "Epoch 5/6\n",
            "846/846 [==============================] - ETA: 0s - loss: 0.0363\n",
            "Epoch 5: val_loss did not improve from 0.05458\n",
            "846/846 [==============================] - 9s 10ms/step - loss: 0.0363 - val_loss: 0.0578\n",
            "Epoch 6/6\n",
            "843/846 [============================>.] - ETA: 0s - loss: 0.0352\n",
            "Epoch 6: val_loss did not improve from 0.05458\n",
            "846/846 [==============================] - 8s 9ms/step - loss: 0.0352 - val_loss: 0.0562\n",
            "\n",
            "Training Complete!\n"
          ]
        }
      ],
      "source": [
        "#Z = 8760, trainN = 8460\n",
        "batch_size = 10\n",
        "num_epochs = 8\n",
        "lead=12\n",
        "count=0\n",
        "for loop in fileList_train:\n",
        "    print('******************** counter ******************** COUNT =',count)\n",
        "    File=nc.Dataset(loop)\n",
        "    Z=np.asarray(File['z'])\n",
        "    trainN=np.size(Z,0)-300\n",
        "    Z=(Z-M)/sdev\n",
        "    \n",
        "    x_train=Z[0:trainN,:,:]\n",
        "    x_train=x_train.reshape([np.size(x_train,0),32,64,1])\n",
        "    y_train=Z[lead:trainN+lead,:,:]\n",
        "    y_train=y_train.reshape([np.size(y_train,0),32,64,1])\n",
        "    \n",
        "    x_val= Z[trainN+lead:np.size(Z,0)-lead,:,:]\n",
        "    x_val=x_val.reshape([np.size(x_val,0),32,64,1])\n",
        "    \n",
        "    y_val= Z[trainN+lead*2:np.size(Z,0),:,:]\n",
        "    y_val=y_val.reshape([np.size(y_val,0),32,64,1])\n",
        "\n",
        "\n",
        "    if (count>0):\n",
        "        model = unet_baseline()\n",
        "        model.compile(loss=root_mean_squared_error, optimizer='adam')\n",
        "        model.load_weights('/content/drive/MyDrive/DDWP/persistence_rmse_2.h5')\n",
        "        hist = model.fit(x_train, y_train,\n",
        "                       batch_size = batch_size,\n",
        "             verbose=1,\n",
        "             epochs = 6,\n",
        "             validation_data=(x_val,y_val),shuffle=True,\n",
        "             callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                        min_delta=0,\n",
        "                                        patience=5, # just to make sure we use a lot of patience before stopping\n",
        "                                        verbose=0, mode='auto'),\n",
        "                       keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/DDWP/persistence_rmse_2.h5', monitor='val_loss',\n",
        "                                                    verbose=1, save_best_only=True,\n",
        "                                                    save_weights_only=True, mode='auto', period=1),history]\n",
        "             )\n",
        "\n",
        "    else:\n",
        "        hist = model.fit(x_train, y_train,\n",
        "                       batch_size = batch_size,\n",
        "             verbose=1,\n",
        "             epochs = 6,\n",
        "             validation_data=(x_val,y_val),shuffle=True,\n",
        "             callbacks=[keras.callbacks.EarlyStopping(monitor='val_loss',\n",
        "                                        min_delta=0,\n",
        "                                        patience=5, # just to make sure we use a lot of patience before stopping\n",
        "                                        verbose=0, mode='auto'),\n",
        "                       keras.callbacks.ModelCheckpoint('/content/drive/MyDrive/DDWP/persistence_rmse_2.h5', monitor='val_loss',\n",
        "                                                    verbose=1, save_best_only=True,\n",
        "                                                    save_weights_only=True, mode='auto', period=1),history]\n",
        "             )\n",
        "    count=count+1\n",
        "\n",
        "print(\"\\nTraining Complete!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.12 ('mtp')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    },
    "vscode": {
      "interpreter": {
        "hash": "4193054334bc3c370bcbddfa2df63480274268dcb26021259c42d4693145ae24"
      }
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}